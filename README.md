# Biases in NLP Models Upon Mentions of Disabilities

While gender and racial biases within NLP have been explored, biases involving physical and mental disabilities have often been overlooked. In this repository, we recreate the [Social Biases in NLP Models as Barriers for Persons with Disabilities](https://aclanthology.org/2020.acl-main.487/) paper in order to reproduce the uncovering of disability-related biases by 1) trialing toxicity and sentiment classification models and 2) using mask-term predictions to understand the learned representations of language of models. Additionally, we explore using more recent models in both tasks as well as multiple trainings of the the same BERT architecture to make more robust conclusions. 

Conclusions and results for this project are found on the [report](./reports/final_report.pdf) and [poster](./reports/poster.pdf).
